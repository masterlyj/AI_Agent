import logging

from typing import Dict, List, Any, Annotated, TypedDict, Optional
from langchain_community.document_loaders import ArxivLoader
from langchain_community.document_transformers import LongContextReorder
from langchain_core.documents import Document
from langchain_community.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.docstore.in_memory import InMemoryDocstore
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from faiss import IndexFlatL2
from langgraph.types import Command


from .state import Paper_Study_State
from .llm import get_llm
from .lightrag_core import LightRAGKnowledgeGraph

# --- åˆå§‹åŒ– ---
logger = logging.getLogger(__name__)

text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000, chunk_overlap=100,
    separators=["\n\n", "\n", ".", ";", ",", " "],
)

llm = get_llm()
long_reorder = LongContextReorder()

chat_prompt = ChatPromptTemplate.from_messages([
    ("system",
     "ä½ æ˜¯ä¸€ä¸ªæ–‡æ¡£èŠå¤©æœºå™¨äººã€‚è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯å›žç­”ç”¨æˆ·é—®é¢˜ã€‚\n"
     "ç”¨æˆ·é—®é¢˜ï¼š{query}\n\n"
     "å¯¹è¯åŽ†å²æ£€ç´¢ï¼š\n{history_retrieved}\n\n"
     "ä¼ ç»Ÿæ–‡æ¡£æ£€ç´¢ï¼š\n{context_retrieved}\n\n"
     "çŸ¥è¯†å›¾è°±å¢žå¼ºæ£€ç´¢ï¼š\n{graph_context}\n\n"
     "è¯·ä¼˜å…ˆä½¿ç”¨çŸ¥è¯†å›¾è°±ä¿¡æ¯ï¼Œç»“åˆä¼ ç»Ÿæ£€ç´¢å†…å®¹ï¼Œç”¨å¯¹è¯å¼è¯­æ°”å›žå¤ã€‚"
     "å¦‚æžœçŸ¥è¯†å›¾è°±æä¾›äº†æ›´ç›¸å…³çš„ä¿¡æ¯ï¼Œè¯·é‡ç‚¹å‚è€ƒã€‚"
    ),
    ("user", "{query}")
])

# --- å·¥å…·å‡½æ•° ---
def docs2str(docs: List[Document]) -> str:
    return "\n\n".join(f"[{i+1}] {doc.page_content}" for i, doc in enumerate(docs))

def default_FAISS(embedder) -> FAISS:
    test_vec = embedder.embed_query("test")
    dim = len(test_vec)
    return FAISS(
        embedding_function=embedder,
        index=IndexFlatL2(dim),
        docstore=InMemoryDocstore(),
        index_to_docstore_id={},
        normalize_L2=False
    )

# --- èŠ‚ç‚¹å‡½æ•° ---
def load_and_chunk_papers(state: Paper_Study_State) -> Command:
    arxiv_ids = state["arXiv_ids"]
    all_chunks: List[Document] = []
    metadata_list = []

    logger.info(f"å¼€å§‹ä»Ž arXiv åŠ è½½ {len(arxiv_ids)} ç¯‡è®ºæ–‡...")

    for arxiv_id in arxiv_ids:
        print(f"æ­£åœ¨åŠ è½½è®ºæ–‡: {arxiv_id}")
        try:
            docs = ArxivLoader(query=arxiv_id).load()
            if not docs:
                logger.warning(f"âš ï¸ æœªèƒ½åŠ è½½åˆ°æ–‡æ¡£: {arxiv_id}")
                continue
            doc = docs[0]

            if "References" in doc.page_content:
                doc.page_content = doc.page_content[:doc.page_content.index("References")]

            metadata_list.append(doc.metadata)
            chunks = text_splitter.split_documents([doc])
            filtered_chunks = [c for c in chunks if len(c.page_content) > 200]
            all_chunks.extend(filtered_chunks)

        except Exception as e:
            logger.error(f"âŒ åŠ è½½è®ºæ–‡ {arxiv_id} æ—¶å‡ºé”™: {e}")
            continue

    doc_summary = "å¯ç”¨è®ºæ–‡åˆ—è¡¨ï¼š\n"
    for meta in metadata_list:
        title = meta.get("Title", "æœªçŸ¥æ ‡é¢˜")
        doc_summary += f" - {title}\n"

    summary_doc = Document(
        page_content=doc_summary,
        metadata={"source": "paper_summary", "type": "global_context"}
    )
    all_chunks.insert(0, summary_doc)

    logger.info(f"âœ… æ€»å…±åˆ‡åˆ†å—æ•°: {len(all_chunks)}")
    return Command(
        goto="embed_and_index",
        update={"context": all_chunks}
    )

def embed_and_index(state: Paper_Study_State) -> Command:
    embedder = state["embedder"]
    docs = state["context"]
    use_lightrag = state.get("use_lightrag", False)

    print(f"æ­£åœ¨ä¸º {len(docs)} ä¸ªæ–‡æ¡£å—ç”ŸæˆåµŒå…¥...")
    main_vstore = FAISS.from_documents(docs, embedder)
    convstore = default_FAISS(embedder)

    print(f"âœ… å‘é‡åº“æž„å»ºå®Œæˆï¼Œå…± {main_vstore.index.ntotal} ä¸ªå‘é‡")
    
    # æž„å»ºçŸ¥è¯†å›¾è°±ï¼ˆå¦‚æžœå¯ç”¨ LightRAGï¼‰
    knowledge_graph = None
    if use_lightrag:
        print("ðŸ§  å¼€å§‹æž„å»º LightRAG çŸ¥è¯†å›¾è°±...")
        knowledge_graph = LightRAGKnowledgeGraph(embedder)
        graph_result = knowledge_graph.build_graph(docs)
        print(f"âœ… çŸ¥è¯†å›¾è°±æž„å»ºå®Œæˆ: {graph_result['graph_stats']}")

    return Command(
        goto="retrieve",
        update={
            "vectorstore": main_vstore,
            "convstore": convstore,
            "knowledge_graph": knowledge_graph
        }
    )

def retrieve(state: Paper_Study_State) -> Command:
    question = state["query"]
    vectorstore = state["vectorstore"]
    convstore = state["convstore"]
    knowledge_graph = state.get("knowledge_graph")

    # ä¼ ç»Ÿå‘é‡æ£€ç´¢
    docs_context = vectorstore.as_retriever(search_kwargs={"k": 5}).invoke(question)
    reordered_context = long_reorder.transform_documents(docs_context)
    context_str = docs2str(reordered_context)

    # LightRAG å›¾å¢žå¼ºæ£€ç´¢
    graph_context = ""
    if knowledge_graph:
        print("ðŸ” ä½¿ç”¨ LightRAG è¿›è¡Œå›¾å¢žå¼ºæ£€ç´¢...")
        graph_docs = knowledge_graph.graph_enhanced_retrieve(question, k=3)
        if graph_docs:
            graph_context = docs2str(graph_docs)
            print(f"âœ… ä»ŽçŸ¥è¯†å›¾è°±æ£€ç´¢åˆ° {len(graph_docs)} ä¸ªç›¸å…³æ–‡æ¡£")
        else:
            print("âš ï¸ çŸ¥è¯†å›¾è°±æœªæ£€ç´¢åˆ°ç›¸å…³æ–‡æ¡£")

    # å¯¹è¯åŽ†å²æ£€ç´¢
    docs_history = convstore.as_retriever(search_kwargs={"k": 3}).invoke(question)
    reordered_history = long_reorder.transform_documents(docs_history)
    history_str = docs2str(reordered_history) if docs_history else "æ— ç›¸å…³å¯¹è¯åŽ†å²"

    return Command(
        goto="generate_answer",
        update={
            "context_retrieved": context_str,
            "graph_context": graph_context,
            "history_retrieved": history_str
        }
    )

def generate_answer(state: Paper_Study_State) -> Command:
    chain = chat_prompt | llm | StrOutputParser()
    answer = chain.invoke({
        "query": state["query"],
        "context_retrieved": state["context_retrieved"],
        "graph_context": state.get("graph_context", ""),
        "history_retrieved": state["history_retrieved"]
    })
    return Command(
        goto="update_convstore",
        update={"answer": answer}
    )

def update_convstore(state: Paper_Study_State) -> Command:
    convstore = state["convstore"]
    convstore.add_texts([
        f"ç”¨æˆ·: {state['query']}",
        f"åŠ©æ‰‹: {state['answer']}"
    ])
    return Command(
        goto="__end__",
        update={"convstore": convstore}
    )