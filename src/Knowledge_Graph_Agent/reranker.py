import torch
import numpy as np
from tqdm import tqdm
from typing import List, Union, Tuple
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from BCEmbedding.utils import logger_wrapper
import os
from pathlib import Path
import requests
import json

logger = logger_wrapper('BCEmbedding.models.RerankerModel')

class RerankerModel:
    def __init__(
            self,
            model_name_or_path: str = 'maidalun1020/bce-reranker-base_v1',
            use_fp16: bool = False,
            device: str = None,
            top_k: int = 20,
            **kwargs
    ):
        # æ£€æŸ¥æ˜¯å¦æ˜¯æœ¬åœ°è·¯å¾„
        is_local_path = os.path.exists(model_name_or_path) and os.path.isdir(model_name_or_path)
        
        if is_local_path:
            logger.info(f"æ­£åœ¨ä»æœ¬åœ°è·¯å¾„åŠ è½½æ¨¡å‹: {model_name_or_path}")
            # ç¡®ä¿è·¯å¾„å­˜åœ¨
            model_path = Path(model_name_or_path)
            if not model_path.exists():
                raise ValueError(f"æœ¬åœ°æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_name_or_path}")
        else:
            logger.info(f"æ­£åœ¨ä»Hugging Face HubåŠ è½½æ¨¡å‹: {model_name_or_path}")
        
        # åŠ è½½tokenizerå’Œæ¨¡å‹
        try:
            self.tokenizer = AutoTokenizer.from_pretrained(
                model_name_or_path, 
                local_files_only=is_local_path,
                **kwargs
            )
            self.model = AutoModelForSequenceClassification.from_pretrained(
                model_name_or_path,
                local_files_only=is_local_path,
                **kwargs
            )
            logger.info(f"âœ… æˆåŠŸåŠ è½½æ¨¡å‹: {model_name_or_path}")
        except Exception as e:
            logger.error(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
            raise
        
        num_gpus = torch.cuda.device_count()
        if device is None:
            self.device = "cuda" if num_gpus > 0 else "cpu"
        else:
            self.device = 'cuda:{}'.format(int(device)) if device.isdigit() else device

        if self.device == "cpu":
            self.num_gpus = 0
        elif self.device.startswith('cuda:') and num_gpus > 0:
            self.num_gpus = 1
        elif self.device == "cuda":
            self.num_gpus = num_gpus
        else:
            raise ValueError("Please input valid device: 'cpu', 'cuda', 'cuda:0', '0' !")

        if use_fp16:
            self.model.half()

        self.model.eval()
        self.model = self.model.to(self.device)

        if self.num_gpus > 1:
            self.model = torch.nn.DataParallel(self.model)

        logger.info(f"Execute device: {self.device};\t gpu num: {self.num_gpus};\t use fp16: {use_fp16}")

        self.max_length = kwargs.get('max_length', 512)
        self.overlap_tokens = kwargs.get('overlap_tokens', 80)
        self.rerank_top_k = top_k

    def compute_score(
            self,
            sentence_pairs: Union[List[Tuple[str, str]], Tuple[str, str]],
            batch_size: int = 256,
            max_length: int = 512,
            enable_tqdm: bool = True,
            **kwargs
    ):
        if self.num_gpus > 1:
            batch_size = batch_size * self.num_gpus

        assert isinstance(sentence_pairs, list)
        if isinstance(sentence_pairs[0], str):
            sentence_pairs = [sentence_pairs]

        with torch.no_grad():
            scores_collection = []
            for sentence_id in tqdm(range(0, len(sentence_pairs), batch_size), desc='Calculate scores',
                                    disable=not enable_tqdm):
                sentence_pairs_batch = sentence_pairs[sentence_id:sentence_id + batch_size]
                inputs = self.tokenizer(
                    sentence_pairs_batch,
                    padding=True,
                    truncation=True,
                    max_length=max_length,
                    return_tensors="pt"
                )
                inputs_on_device = {k: v.to(self.device) for k, v in inputs.items()}
                scores = self.model(**inputs_on_device, return_dict=True).logits.view(-1, ).float()
                scores = torch.sigmoid(scores)
                scores_collection.extend(scores.cpu().numpy().tolist())

        # å§‹ç»ˆè¿”å›åˆ—è¡¨ï¼Œå³ä½¿åªæœ‰ä¸€ä¸ªå…ƒç´ 
        return scores_collection

    def rerank(
            self,
            query: str,
            passages: List[str],
            batch_size: int = 256,
            **kwargs
    ):
        """
        å¯¹ç»™å®šçš„æŸ¥è¯¢å’Œæ®µè½åˆ—è¡¨è¿›è¡Œé‡æ–°æ’åºã€‚
        """
        # è¿‡æ»¤æ‰æ— æ•ˆçš„æ®µè½
        passages = [p for p in passages if isinstance(p, str) and len(p) > 0]
        if not query or not passages:
            return {'rerank_passages': [], 'rerank_scores': [], 'rerank_ids': []}

        # 1. åˆ›å»ºæŸ¥è¯¢å’Œæ®µè½çš„é…å¯¹
        sentence_pairs = [[query, passage] for passage in passages]

        # 2. ä½¿ç”¨ compute_score æ–¹æ³•ç›´æ¥è®¡ç®—æ‰€æœ‰é…å¯¹çš„åˆ†æ•°
        all_scores = self.compute_score(sentence_pairs, batch_size=batch_size, **kwargs)
        
        # ç¡®ä¿ all_scores æ˜¯åˆ—è¡¨
        if not isinstance(all_scores, list):
            all_scores = [all_scores]

        # 3. æ ¹æ®åˆ†æ•°è¿›è¡Œæ’åº
        # np.argsort è¿”å›çš„æ˜¯æ’åºåçš„åŸå§‹ç´¢å¼•
        sorted_indices = np.argsort(all_scores)[::-1].tolist()

        # 4. æ ¹æ®æ’åºåçš„ç´¢å¼•é‡æ–°ç»„ç»‡æ®µè½å’Œåˆ†æ•°
        sorted_passages = [passages[i] for i in sorted_indices]
        sorted_scores = [all_scores[i] for i in sorted_indices]

        return {
            'rerank_passages': sorted_passages,
            'rerank_scores': sorted_scores,
            'rerank_ids': sorted_indices
        }


class VLLMRerankerModel:
    """åŸºäºvLLM APIçš„Rerankæ¨¡å‹ï¼Œæ”¯æŒQwen3-Reranker instructionæ ¼å¼"""
    
    def __init__(
            self,
            base_url: str,
            model: str,
            api_key: str = "EMPTY",
            top_k: int = 20,
            timeout: int = 60,
            instruction: str = "ç»™å®šä¸€ä¸ªæŸ¥è¯¢ï¼Œæ£€ç´¢èƒ½å›ç­”è¯¥æŸ¥è¯¢çš„ç›¸å…³æ–‡æ¡£",
            **kwargs
    ):
        """
        åˆå§‹åŒ–vLLM Reranker
        
        Args:
            base_url: vLLMæœåŠ¡çš„base URLï¼Œä¾‹å¦‚ "http://localhost:18890/v1"
            model: æ¨¡å‹åç§°
            api_key: APIå¯†é’¥ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸º"EMPTY"ï¼‰
            top_k: è¿”å›çš„top-kç»“æœæ•°é‡
            timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            instruction: RerankæŒ‡ä»¤ï¼Œç”¨äºQwen3-Rerankerç­‰æ¨¡å‹
        """
        self.base_url = base_url.rstrip('/')
        self.model = model
        self.api_key = api_key
        self.rerank_top_k = top_k
        self.timeout = timeout
        self.instruction = instruction
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºQwen3-Rerankeræ¨¡å‹
        self.is_qwen3_reranker = "qwen3-reranker" in model.lower()
        
        logger.info(f"âœ… åˆå§‹åŒ–vLLM Reranker: {model} (base_url={base_url})")
        if self.is_qwen3_reranker:
            logger.info(f"ğŸ“ ä½¿ç”¨Qwen3-RerankeræŒ‡ä»¤æ ¼å¼: {instruction}")
    
    def compute_score(
            self,
            sentence_pairs: Union[List[Tuple[str, str]], Tuple[str, str]],
            **kwargs
    ) -> List[float]:
        """
        è®¡ç®—å¥å­å¯¹çš„ç›¸å…³æ€§åˆ†æ•°
        
        Args:
            sentence_pairs: å¥å­å¯¹åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º [query, passage]
        
        Returns:
            åˆ†æ•°åˆ—è¡¨ï¼Œä¸è¾“å…¥æ–‡æ¡£é¡ºåºä¸¥æ ¼å¯¹åº”
        """
        if isinstance(sentence_pairs[0], str):
            sentence_pairs = [sentence_pairs]
        
        num_docs = len(sentence_pairs)
        logger.info(f"ğŸ“Š vLLM Rerank: ä¸€æ¬¡æ€§å¤„ç† {num_docs} ä¸ªæ–‡æ¡£")
        
        try:
            # è°ƒç”¨vLLM rerank API
            url = f"{self.base_url}/rerank"
            
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {self.api_key}"
            }
            
            # æå–queryå’Œdocuments
            query = sentence_pairs[0][0] if len(sentence_pairs) > 0 else ""
            documents = [pair[1] for pair in sentence_pairs]
            
            # ä¸ºQwen3-Rerankeræ·»åŠ instructionå’ŒDocumentå‰ç¼€
            if self.is_qwen3_reranker:
                query_with_instruction = f"<Instruct>: {self.instruction}\n<Query>: {query}"
                documents_with_prefix = [f"<Document>: {doc}" for doc in documents]
            else:
                query_with_instruction = query
                documents_with_prefix = documents
            
            payload = {
                "model": self.model,
                "query": query_with_instruction,
                "documents": documents_with_prefix
            }
            
            response = requests.post(
                url,
                headers=headers,
                json=payload,
                timeout=self.timeout
            )
            
            if response.status_code == 200:
                result = response.json()
                results_list = result.get("results", [])
                
                # é‡è¦ï¼švLLMè¿”å›çš„resultsæ˜¯æŒ‰scoreæ’åºçš„ï¼Œéœ€è¦æŒ‰indexé‡æ–°æ’åº
                # ä»¥ç¡®ä¿åˆ†æ•°åˆ—è¡¨ä¸è¾“å…¥documentsåˆ—è¡¨é¡ºåºä¸€è‡´
                sorted_results = sorted(results_list, key=lambda x: x["index"])
                scores = [item["relevance_score"] for item in sorted_results]
                
                # éªŒè¯è¿”å›çš„åˆ†æ•°æ•°é‡ä¸è¾“å…¥æ–‡æ¡£æ•°é‡ä¸€è‡´
                if len(scores) != num_docs:
                    logger.error(f"âŒ APIè¿”å›çš„ç»“æœæ•°é‡ ({len(scores)}) ä¸è¾“å…¥æ–‡æ¡£æ•°é‡ ({num_docs}) ä¸åŒ¹é…")
                    return [0.0] * num_docs
                
                logger.info(f"âœ… vLLM Rerank å®Œæˆ: {num_docs} ä¸ªæ–‡æ¡£")
                return scores
            else:
                logger.error(f"âŒ vLLM Rerank APIé”™è¯¯: {response.status_code} - {response.text}")
                return [0.0] * num_docs
                
        except requests.Timeout:
            logger.error(f"âŒ vLLM Rerank APIè¶…æ—¶")
            return [0.0] * num_docs
        except Exception as e:
            logger.error(f"âŒ è°ƒç”¨vLLM Rerank APIå¤±è´¥: {e}")
            return [0.0] * num_docs
    
    def rerank(
            self,
            query: str,
            passages: List[str],
            **kwargs
    ):
        """
        å¯¹ç»™å®šçš„æŸ¥è¯¢å’Œæ®µè½åˆ—è¡¨è¿›è¡Œé‡æ–°æ’åº
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            passages: æ®µè½åˆ—è¡¨
        
        Returns:
            åŒ…å«é‡æ’åºç»“æœçš„å­—å…¸
        """
        # è¿‡æ»¤æ‰æ— æ•ˆçš„æ®µè½
        passages = [p for p in passages if isinstance(p, str) and len(p) > 0]
        if not query or not passages:
            return {'rerank_passages': [], 'rerank_scores': [], 'rerank_ids': []}
        
        # åˆ›å»ºæŸ¥è¯¢å’Œæ®µè½çš„é…å¯¹
        sentence_pairs = [[query, passage] for passage in passages]
        
        # è®¡ç®—åˆ†æ•°ï¼ˆä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰æ–‡æ¡£ï¼‰
        all_scores = self.compute_score(sentence_pairs, **kwargs)
        
        # ç¡®ä¿ all_scores æ˜¯åˆ—è¡¨
        if not isinstance(all_scores, list):
            all_scores = [all_scores]
        
        # æ ¹æ®åˆ†æ•°è¿›è¡Œæ’åº
        sorted_indices = np.argsort(all_scores)[::-1].tolist()
        
        # æ ¹æ®æ’åºåçš„ç´¢å¼•é‡æ–°ç»„ç»‡æ®µè½å’Œåˆ†æ•°
        sorted_passages = [passages[i] for i in sorted_indices]
        sorted_scores = [all_scores[i] for i in sorted_indices]
        
        return {
            'rerank_passages': sorted_passages,
            'rerank_scores': sorted_scores,
            'rerank_ids': sorted_indices
        }