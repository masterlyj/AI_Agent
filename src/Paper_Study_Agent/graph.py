import logging

from typing import Dict, List, Any, Annotated, TypedDict, Optional
from langchain_community.document_loaders import ArxivLoader
from langchain_community.document_transformers import LongContextReorder
from langchain_core.documents import Document
from langchain_community.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.docstore.in_memory import InMemoryDocstore
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from faiss import IndexFlatL2
from langgraph.types import Command


from .state import Paper_Study_State
from .llm import get_llm
from .reranker import RerankerModel 


# --- åˆå§‹åŒ– ---
logger = logging.getLogger(__name__)

text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000, chunk_overlap=100,
    separators=["\n\n", "\n", ".", ";", ",", " "],
)

llm = get_llm()
long_reorder = LongContextReorder()

chat_prompt = ChatPromptTemplate.from_messages([
    ("system",
     "ä½ æ˜¯ä¸€ä¸ªæ–‡æ¡£èŠå¤©æœºå™¨äººã€‚è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯å›žç­”ç”¨æˆ·é—®é¢˜ã€‚\n"
     "å¯¹è¯åŽ†å²æ£€ç´¢ï¼š\n{history_retrieved}\n\n"
     "æ–‡æ¡£æ£€ç´¢ï¼š\n{context_retrieved}\n\n"
     "ä»…æ ¹æ®æ£€ç´¢å†…å®¹å›žç­”ï¼Œç”¨å¯¹è¯å¼è¯­æ°”å›žå¤å¹¶ç»™å‡ºåŽŸæ–‡å†…å®¹ï¼ˆå¦‚æžœåŽŸæ–‡å†…å®¹è¯­è¨€ä¸Žç”¨æˆ·é—®é¢˜è¯­è¨€ä¸ä¸€è‡´ï¼Œè¯·å°†åŽŸæ–‡å†…å®¹ä»¥åŠç¿»è¯‘æˆç”¨äºŽé—®é¢˜è¯­è¨€çš„å†…å®¹ä¸€èµ·è¿”å›žï¼‰ã€‚"
    ),
    ("user", "{query}")
])

# --- å·¥å…·å‡½æ•° ---
def docs2str(docs: List[Document]) -> str:
    return "\n\n".join(f"[{i+1}] {doc.page_content}" for i, doc in enumerate(docs))

def default_FAISS(embedder) -> FAISS:
    test_vec = embedder.embed_query("test")
    dim = len(test_vec)
    return FAISS(
        embedding_function=embedder,
        index=IndexFlatL2(dim),
        docstore=InMemoryDocstore(),
        index_to_docstore_id={},
        normalize_L2=False
    )

# --- èŠ‚ç‚¹å‡½æ•° ---
def load_and_chunk_papers(state: Paper_Study_State) -> Command:
    arxiv_ids = state["arXiv_ids"]
    all_chunks: List[Document] = []
    metadata_list = []

    logger.info(f"å¼€å§‹ä»Ž arXiv åŠ è½½ {len(arxiv_ids)} ç¯‡è®ºæ–‡...")

    for arxiv_id in arxiv_ids:
        print(f"æ­£åœ¨åŠ è½½è®ºæ–‡: {arxiv_id}")
        try:
            docs = ArxivLoader(query=arxiv_id).load()
            if not docs:
                logger.warning(f"âš ï¸ æœªèƒ½åŠ è½½åˆ°æ–‡æ¡£: {arxiv_id}")
                continue
            doc = docs[0]

            if "References" in doc.page_content:
                doc.page_content = doc.page_content[:doc.page_content.index("References")]

            metadata_list.append(doc.metadata)
            chunks = text_splitter.split_documents([doc])
            filtered_chunks = [c for c in chunks if len(c.page_content) > 200]
            all_chunks.extend(filtered_chunks)

        except Exception as e:
            logger.error(f"âŒ åŠ è½½è®ºæ–‡ {arxiv_id} æ—¶å‡ºé”™: {e}")
            continue

    doc_summary = "å¯ç”¨è®ºæ–‡åˆ—è¡¨ï¼š\n"
    for meta in metadata_list:
        title = meta.get("Title", "æœªçŸ¥æ ‡é¢˜")
        doc_summary += f" - {title}\n"

    summary_doc = Document(
        page_content=doc_summary,
        metadata={"source": "paper_summary", "type": "global_context"}
    )
    all_chunks.insert(0, summary_doc)

    logger.info(f"âœ… æ€»å…±åˆ‡åˆ†å—æ•°: {len(all_chunks)}")
    return Command(
        goto="embed_and_index",
        update={"context": all_chunks}
    )

def embed_and_index(state: Paper_Study_State) -> Command:
    embedder = state["embedder"]
    docs = state["context"]

    print(f"æ­£åœ¨ä¸º {len(docs)} ä¸ªæ–‡æ¡£å—ç”ŸæˆåµŒå…¥...")
    main_vstore = FAISS.from_documents(docs, embedder)
    convstore = default_FAISS(embedder)

    print(f"âœ… å‘é‡åº“æž„å»ºå®Œæˆï¼Œå…± {main_vstore.index.ntotal} ä¸ªå‘é‡")
    return Command(
        goto="retrieve",
        update={
            "vectorstore": main_vstore,
            "convstore": convstore
        }
    )

def retrieve(state: Paper_Study_State) -> Command:
    question = state["query"]
    vectorstore = state["vectorstore"]
    convstore = state["convstore"]

    docs_context = vectorstore.as_retriever(search_kwargs={"k": 5}).invoke(question)
    reordered_context = long_reorder.transform_documents(docs_context)
    context_str = docs2str(reordered_context)

    docs_history = convstore.as_retriever(search_kwargs={"k": 3}).invoke(question)
    reordered_history = long_reorder.transform_documents(docs_history)
    history_str = docs2str(reordered_history) if docs_history else "æ— ç›¸å…³å¯¹è¯åŽ†å²"

    return Command(
        goto="rerank",
        update={
            "docs_for_rerank": docs_context,
            "history_retrieved": history_str
        }
    )
# --- æ–°å¢ž ---
def rerank(state: Paper_Study_State) -> Command:
    """
    å¯¹ä¼ ç»Ÿæ£€ç´¢è¿”å›žçš„æ–‡æ¡£è¿›è¡Œç²¾æŽ’ã€‚
    """
    print("ðŸš€ å¼€å§‹ç²¾æŽ’...")
    reranker = state.get("reranker")
    
    # å¦‚æžœæ²¡æœ‰é…ç½® rerankerï¼Œåˆ™ç›´æŽ¥ä½¿ç”¨ç²—æŽ’ç»“æžœ
    if not reranker:
        print("âš ï¸ æœªé…ç½® Rerankerï¼Œè·³è¿‡ç²¾æŽ’æ­¥éª¤ã€‚")
        docs_to_rerank = state.get("docs_for_rerank", [])
        reordered_context = long_reorder.transform_documents(state["docs_for_rerank"])
        context_str = docs2str(reordered_context)
        return Command(
            goto="generate_answer",
            update={"context_retrieved": context_str}
        )
        
    query = state["query"]
    docs_to_rerank = state["docs_for_rerank"]
    
    if not docs_to_rerank:
        print("æ²¡æœ‰æ–‡æ¡£éœ€è¦ç²¾æŽ’ã€‚")
        return Command(
            goto="generate_answer",
            update={"context_retrieved": "æ— ç›¸å…³æ–‡æ¡£"}
        )

    # æå–æ–‡æ¡£å†…å®¹è¿›è¡Œç²¾æŽ’
    passages = [doc.page_content for doc in docs_to_rerank]
    
    # è°ƒç”¨ rerank æ–¹æ³•
    results = reranker.rerank(query, passages)
    rerank_ids = results.get('rerank_ids', [])
    rerank_scores = results.get('rerank_scores', [])
    # æŒ‰ç…§ rerank çš„é¡ºåºé‡æ–°ç»„ç»‡åŽŸå§‹ Document å¯¹è±¡
    reranked_docs = [docs_to_rerank[i] for i in rerank_ids]

    # æ‰“å°ç²¾æŽ’ç»“æžœ
    print("\n--- Reranker æ‰“åˆ†ç»“æžœ (ä»Žé«˜åˆ°ä½Ž) ---")
    # ä½¿ç”¨ zip å°†æ–‡æ¡£å’Œåˆ†æ•°å®‰å…¨åœ°é…å¯¹åœ¨ä¸€èµ·ï¼Œè¿™æ ·æ›´ç¨³å¥
    for doc, score in zip(reranked_docs, rerank_scores):
        # æˆªå–æ–‡æ¡£å†…å®¹çš„å‰100ä¸ªå­—ç¬¦ä½œä¸ºé¢„è§ˆï¼Œå¹¶æ›¿æ¢æ¢è¡Œç¬¦
        content_snippet = doc.page_content.replace("\n", " ") + "..."
        
        print(f"  åˆ†æ•°: {score:.4f} | å†…å®¹: '{content_snippet}'")
    print("---------------------------------------\n")
    
    # é€‰æ‹© Top-K (ä¾‹å¦‚ 3 ä¸ª) ä½œä¸ºæœ€ç»ˆä¸Šä¸‹æ–‡
    top_k = 3
    final_docs = reranked_docs[:top_k]
    print(f"âœ… ç²¾æŽ’å®Œæˆï¼Œé€‰å– Top {top_k} æ–‡æ¡£ã€‚")
    
    context_str = docs2str(final_docs)
    
    return Command(
        goto="generate_answer",
        update={"context_retrieved": context_str}
    )
def generate_answer(state: Paper_Study_State) -> Command:
    chain = chat_prompt | llm | StrOutputParser()
    answer = chain.invoke({
        "query": state["query"],
        "context_retrieved": state["context_retrieved"],
        "history_retrieved": state["history_retrieved"]
    })
    return Command(
        goto="update_convstore",
        update={"answer": answer}
    )

def update_convstore(state: Paper_Study_State) -> Command:
    convstore = state["convstore"]
    convstore.add_texts([
        f"ç”¨æˆ·: {state['query']}",
        f"åŠ©æ‰‹: {state['answer']}"
    ])
    return Command(
        goto="__end__",
        update={"convstore": convstore}
    )