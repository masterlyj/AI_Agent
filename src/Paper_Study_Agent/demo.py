import gradio as gr
from .app import PaperChatBot

# é…ç½®
ARXIV_IDS = ["2410.05779", "2404.16130"]
EMBEDDING_CONFIG = {
    "type": "ollama",
    "model": "qwen3-embedding:0.6b",
    "base_url": "http://localhost:11434"
}
# ç¤ºä¾‹ï¼šä½¿ç”¨æœ¬åœ° HuggingFace/modelscope åµŒå…¥æ¨¡å‹
# EMBEDDING_CONFIG = {
#     "type": "hf",
#     "model_name": r"D:\Codes\modelscope\nlp_gte_sentence-embedding_chinese-base",
#     "model_kwargs": {"device": "cpu"},  # æˆ– "cuda"
#     "encode_kwargs": {"normalize_embeddings": True, "batch_size": 64},
#     "show_progress": True
# }

bot = PaperChatBot(arxiv_ids=ARXIV_IDS, embedding_config=EMBEDDING_CONFIG)

# å¯åŠ¨ Gradio
demo = gr.ChatInterface(
    fn=bot.chat,
    description=bot.get_initial_message(),
    title="ğŸ“š è®ºæ–‡é—®ç­”åŠ©æ‰‹",
    examples=["Graph RAG æ˜¯ä»€ä¹ˆï¼Ÿ", "è¿™ç¯‡è®ºæ–‡æå‡ºäº†å“ªäº›åˆ›æ–°ï¼Ÿ"],
    cache_examples=False,
    type="messages"
).queue()

if __name__ == "__main__":
    demo.launch(debug=True, share=True)