from typing import List
from langgraph.graph import StateGraph, END

from .graph import load_and_chunk_papers, embed_and_index, retrieve, generate_answer, update_convstore
from .state import Paper_Study_State
from .embedding_factory import get_embedder
from .llm import get_llm
from .graph import retrieve, rerank, generate_answer # å¯¼å…¥æ–°èŠ‚ç‚¹
from .reranker import RerankerModel # å¯¼å…¥ RerankerModel å’Œé…ç½®


class PaperChatBot:
    def __init__(self, arxiv_ids: List[str], embedding_config: dict, rerank_config: dict = None):
        self.arxiv_ids = arxiv_ids
        self.embedder = get_embedder(embedding_config)
        self.llm = get_llm()
        # ----------- æ–°å¢: åˆå§‹åŒ– Reranker æ¨¡å‹ -----------
        self.reranker = None
        if rerank_config:
            print("ğŸš€ æ­£åœ¨åŠ è½½ Reranker æ¨¡å‹...")
            self.reranker = RerankerModel(
                model_name_or_path=rerank_config.get("model", 'maidalun1020/bce-reranker-base_v1'),
                device=rerank_config.get("device", None)
            )
        # -----------------------------------------------------
        print("ğŸš€ æ­£åœ¨åˆå§‹åŒ–è®ºæ–‡å‘é‡åº“ï¼Œè¯·ç¨å€™...")
        
        # --- åˆå§‹åŒ–æµç¨‹ï¼šæ‰‹åŠ¨æ‰§è¡ŒèŠ‚ç‚¹ä»¥æ„å»ºå‘é‡åº“ ---
        init_temp_state: Paper_Study_State = {
            "arXiv_ids": arxiv_ids,
            "query": "",
            "context": [],
            "embedder": self.embedder,
            "vectorstore": None,
            "convstore": None,
            "context_retrieved": "",
            "history_retrieved": "",
            "answer": "",
            "messages": [],
        }
        
        # æ‰‹åŠ¨è°ƒç”¨ load_and_chunk_papers
        load_command = load_and_chunk_papers(init_temp_state)
        if load_command.update:
            init_temp_state.update(load_command.update)
        
        # æ‰‹åŠ¨è°ƒç”¨ embed_and_index
        embed_command = embed_and_index(init_temp_state)
        if embed_command.update:
            init_temp_state.update(embed_command.update)
        
        self.base_vectorstore = init_temp_state["vectorstore"]
        self.convstore = init_temp_state["convstore"]

        # --- ä¸»èŠå¤©å›¾å®šä¹‰ ---
        workflow = StateGraph(Paper_Study_State)
        workflow.add_node("retrieve", retrieve)
        workflow.add_node("rerank", rerank) # æ–°å¢ rerank èŠ‚ç‚¹
        workflow.add_node("generate_answer", generate_answer)
        workflow.add_node("update_convstore", update_convstore)

        workflow.set_entry_point("retrieve")
        workflow.add_edge("retrieve", "rerank")
        workflow.add_edge("rerank", "generate_answer")
        workflow.add_edge("generate_answer", "update_convstore")
        workflow.add_edge("update_convstore", END)

        self.graph = workflow.compile()

        # æ„å»ºåˆå§‹æ¶ˆæ¯
        doc_summary = "å¯ç”¨è®ºæ–‡åˆ—è¡¨ï¼š\n"
        for doc in init_temp_state["context"]:
            if doc.metadata.get("type") == "global_context":
                doc_summary = doc.page_content
                break
        self.initial_msg = (
            "ä½ å¥½ï¼æˆ‘æ˜¯ä¸€ä¸ªæ–‡æ¡£èŠå¤©åŠ©æ‰‹ï¼Œæ—¨åœ¨ä¸ºç”¨æˆ·æä¾›å¸®åŠ©ï¼\n"
            f"{doc_summary}\n\næˆ‘èƒ½ä¸ºæ‚¨æä¾›ä»€ä¹ˆå¸®åŠ©ï¼Ÿ"
        )

    def chat(self, message: str, history: List[List[str]]) -> str:
        current_state: Paper_Study_State = {
            "arXiv_ids": self.arxiv_ids,
            "query": message,
            "context": [],
            "embedder": self.embedder,
            "vectorstore": self.base_vectorstore,
            "convstore": self.convstore,
            "context_retrieved": "",
            "history_retrieved": "",
            "answer": "",
            "messages": [],
            "reranker": self.reranker,  # ä¼ é€’ Reranker æ¨¡å‹å®ä¾‹
        }

        result = self.graph.invoke(current_state)
        self.convstore = result["convstore"]
        return result["answer"]

    def get_initial_message(self) -> str:
        return self.initial_msg